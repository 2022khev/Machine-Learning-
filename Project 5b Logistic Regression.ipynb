{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a2ff120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610601b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NonCurrent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NonCurrent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>20.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>30.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Current</td>\n",
       "      <td>23.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  age  education currentSmoker  cigsPerDay BPMeds prevalentStroke  \\\n",
       "0    Male   39        4.0    NonCurrent         0.0     No              No   \n",
       "1  Female   46        2.0    NonCurrent         0.0     No              No   \n",
       "2    Male   48        1.0       Current        20.0     No              No   \n",
       "3  Female   61        3.0       Current        30.0     No              No   \n",
       "4  Female   46        3.0       Current        23.0     No              No   \n",
       "\n",
       "  prevalentHyp diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0           No       No    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1           No       No    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2           No       No    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3          Yes       No    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4           No       No    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"framingham.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4cc52ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'currentSmoker', 'BPMeds', 'prevalentStroke', 'prevalentHyp', 'diabetes']\n"
     ]
    }
   ],
   "source": [
    "feat_object=[i for i in df.columns if df[i].dtypes==\"object\"]\n",
    "print(feat_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5120fd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sex  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
      "0    1   39        4.0              0         0.0     0.0                0   \n",
      "1    0   46        2.0              0         0.0     0.0                0   \n",
      "2    1   48        1.0              1        20.0     0.0                0   \n",
      "3    0   61        3.0              1        30.0     0.0                0   \n",
      "4    0   46        3.0              1        23.0     0.0                0   \n",
      "\n",
      "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
      "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
      "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
      "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
      "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
      "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
      "\n",
      "   TenYearCHD  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           1  \n",
      "4           0  \n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    if i in feat_object:\n",
    "        df[i] =df[i].map({\"Male\":1,\"Female\":0,\"Yes\":1,\"No\":0,\"Current\":1,\"NonCurrent\":0})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2185b1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education column has 105 null values\n",
      "cigsPerDay column has 29 null values\n",
      "BPMeds column has 53 null values\n",
      "totChol column has 50 null values\n",
      "BMI column has 19 null values\n",
      "heartRate column has 1 null values\n",
      "glucose column has 388 null values\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    l= df[i].isna().sum()\n",
    "    if l>0:\n",
    "        print(i,\"column has\",df[i].isna().sum(),\"null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f14ecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex                  int64\n",
      "age                  int64\n",
      "education          float64\n",
      "currentSmoker        int64\n",
      "cigsPerDay         float64\n",
      "BPMeds             float64\n",
      "prevalentStroke      int64\n",
      "prevalentHyp         int64\n",
      "diabetes             int64\n",
      "totChol            float64\n",
      "sysBP              float64\n",
      "diaBP              float64\n",
      "BMI                float64\n",
      "heartRate          float64\n",
      "glucose            float64\n",
      "TenYearCHD           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39616475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education column has mean of  1.9789499153157513\n",
      "cigsPerDay column has mean of  9.003088619624615\n",
      "BPMeds column has mean of  0.02962962962962963\n",
      "totChol column has mean of  236.72158548233045\n",
      "BMI column has mean of  25.80200758473571\n",
      "heartRate column has mean of  75.87892376681614\n",
      "glucose column has mean of  81.96675324675324\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    l= df[i].isna().sum()\n",
    "    if l>0:\n",
    "        means=df[i].mean()\n",
    "        print(i,\"column has mean of \",means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "423266f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in df.columns:\n",
    "    df[i]=df[i].replace(np.NAN,value=df[i].mean())\n",
    "    print(df[i].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "283b6ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target ='TenYearCHD'\n",
    "y=df[target]\n",
    "\n",
    "feat=[i for i in df.columns if 'TenYearCHD' not in i]\n",
    "X=df[feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "086ed1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.848042\n",
      "1    0.151958\n",
      "Name: TenYearCHD, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['TenYearCHD'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98c3310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-optimize\n",
    "# from imblearn.over_sampling import SMOTE,RandomOverSampler,ADASYN\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "# X_train.shape,y_train.shape\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   train_size=0.70,\n",
    "                                                    random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7037ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,RandomOverSampler,ADASYN\n",
    "\n",
    "oversample = SMOTE(random_state=1)\n",
    "X_train_s,y_train_s=oversample.fit_resample(X_train,y_train)\n",
    "\n",
    "# sm = ADASYN(random_state=42)\n",
    "# X_train_ada,y_train_ada=sm.fit_resample(X_train,y_train)\n",
    "\n",
    "# smo=SMOTEENN(random_state=42)\n",
    "# X_trainse,y_trainse=smo.fit_resample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "548f6d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbcf2c2",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b381d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline =make_pipeline(LogisticRegression(solver='saga',max_iter=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b97e1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'logisticregression__penalty':['elasticnet'],\n",
    "    'logisticregression__l1_ratio':[0.2,0.5,0.8],\n",
    "    'logisticregression__C':[0.1,1,10],\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cc1d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline,param_grid,cv=5,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "231bda7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2779364a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 1,\n",
       " 'logisticregression__l1_ratio': 0.2,\n",
       " 'logisticregression__penalty': 'elasticnet'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params =model.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ab0c5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.2, 'logisticregression__penalty': 'elasticnet'}\n",
      "Test_accuracy: 0.8443396226415094\n"
     ]
    }
   ],
   "source": [
    "best_estimator=model.best_estimator_\n",
    "accuracy=best_estimator.score(X_test,y_test)\n",
    "print('Best Parameters:',best_params)\n",
    "print('Test_accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09566342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3749d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54a3905e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.92      1270\n",
      "           1       0.01      0.50      0.01         2\n",
      "\n",
      "    accuracy                           0.84      1272\n",
      "   macro avg       0.50      0.67      0.46      1272\n",
      "weighted avg       1.00      0.84      0.91      1272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2f464",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfe9d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8da0d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline ={\n",
    "    \"enet\":make_pipeline(StandardScaler(),LogisticRegression(penalty='elasticnet',solver='saga',max_iter=1000))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c82fe524",
   "metadata": {},
   "outputs": [],
   "source": [
    "param={\n",
    "    'logisticregression__l1_ratio':[0.2,0.5,0.8],\n",
    "    'logisticregression__C':[0.1,1,10],    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c44ffe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper={\n",
    "    \n",
    "    'enet':param\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "091401ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={}\n",
    "for i in pipeline.keys():\n",
    "    models[i]=GridSearchCV(pipeline[i],hyper[i],cv=5,scoring=\"accuracy\",verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72ec5ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet is trained and tuned\n"
     ]
    }
   ],
   "source": [
    "for i in models.keys():\n",
    "    models[i].fit(X_train,y_train)\n",
    "    print(i,\"is trained and tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8fc92859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8490566037735849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92      1254\n",
      "           1       0.06      0.67      0.11        18\n",
      "\n",
      "    accuracy                           0.85      1272\n",
      "   macro avg       0.53      0.76      0.51      1272\n",
      "weighted avg       0.98      0.85      0.91      1272\n",
      "\n",
      "enet {'enet': array([0, 0, 0, ..., 0, 0, 0], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "y_pred={}\n",
    "for i in models.keys():\n",
    "    y_pred[i]=models[i].predict(X_test)\n",
    "    print(accuracy_score(y_pred[i],y_test))\n",
    "    print(classification_report(y_pred[i],y_test))\n",
    "    print(i,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c766c95",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19d87f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline ={\n",
    "    \"enet\":make_pipeline(StandardScaler(),LogisticRegression(penalty='elasticnet',max_iter=1000)),\n",
    "    \"l1\":make_pipeline(StandardScaler(),LogisticRegression(penalty='l1',max_iter=1000)),\n",
    "    \"l2\":make_pipeline(StandardScaler(),LogisticRegression(penalty='l2',max_iter=1000)),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd1a44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_enet={\n",
    "    'logisticregression__l1_ratio':[0.2,0.5,0.8],\n",
    "    'logisticregression__C':[0.1,1,10], \n",
    "    'logisticregression__solver':['liblinear','saga']\n",
    "    \n",
    "}\n",
    "\n",
    "param_l1={\n",
    "  'logisticregression__C':[0.1,1,10], \n",
    "  'logisticregression__solver':['liblinear','saga']\n",
    "    \n",
    "}\n",
    "\n",
    "param_l2={\n",
    "  'logisticregression__C':[0.1,1,10],    \n",
    "  'logisticregression__solver':['liblinear','saga']  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c250092",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper={\n",
    "    'enet':param_enet,\n",
    "    'l1':param_l1,\n",
    "    'l2':param_l2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6731b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={}\n",
    "for i in pipeline.keys():\n",
    "    models[i]=GridSearchCV(pipeline[i],hyper[i],cv=5,scoring=\"accuracy\",verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "766f13c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet is trained and tuned\n",
      "l1 is trained and tuned\n",
      "l2 is trained and tuned\n"
     ]
    }
   ],
   "source": [
    "for i in models.keys():\n",
    "    models[i].fit(X_train,y_train)\n",
    "    print(i,\"is trained and tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57e45d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".......................... enet model.........................................\n",
      "{'logisticregression__C': 0.1, 'logisticregression__l1_ratio': 0.2, 'logisticregression__solver': 'saga'}\n",
      "\n",
      ".......................... l1 model.........................................\n",
      "{'logisticregression__C': 1, 'logisticregression__solver': 'liblinear'}\n",
      "\n",
      ".......................... l2 model.........................................\n",
      "{'logisticregression__C': 10, 'logisticregression__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "for i in models.keys():\n",
    "    print(\"\\n..........................\",i,\"model.........................................\")\n",
    "    print(models[i].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4aaa486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.2, 'logisticregression__penalty': 'elasticnet'}\n",
      "Test_accuracy: 0.8443396226415094\n",
      "Best Parameters: Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=0.1, l1_ratio=0.2, max_iter=1000,\n",
      "                                    penalty='elasticnet', solver='saga'))])\n",
      "Test_accuracy: 0.8443396226415094\n",
      "Best Parameters: Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=1, max_iter=1000, penalty='l1',\n",
      "                                    solver='liblinear'))])\n",
      "Test_accuracy: 0.8443396226415094\n",
      "Best Parameters: Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(C=10, max_iter=1000, solver='liblinear'))])\n",
      "Test_accuracy: 0.8443396226415094\n"
     ]
    }
   ],
   "source": [
    "best_estimator=model.best_estimator_\n",
    "accuracy=best_estimator.score(X_test,y_test)\n",
    "print('Best Parameters:',best_params)\n",
    "print('Test_accuracy:',accuracy)\n",
    "\n",
    "best_param={}\n",
    "accuracy={}\n",
    "for i in models.keys():\n",
    "    best_param=models[i].best_estimator_\n",
    "    accuracy=best_estimator.score(X_test,y_test)\n",
    "    print('Best Parameters:',best_param)\n",
    "    print('Test_accuracy:',accuracy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa918c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...................... enet model........................................\n",
      "Accuracy: 0.8490566037735849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92      1254\n",
      "           1       0.06      0.67      0.11        18\n",
      "\n",
      "    accuracy                           0.85      1272\n",
      "   macro avg       0.53      0.76      0.51      1272\n",
      "weighted avg       0.98      0.85      0.91      1272\n",
      "\n",
      "\n",
      "...................... l1 model........................................\n",
      "Accuracy: 0.8498427672955975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92      1253\n",
      "           1       0.07      0.68      0.12        19\n",
      "\n",
      "    accuracy                           0.85      1272\n",
      "   macro avg       0.53      0.77      0.52      1272\n",
      "weighted avg       0.98      0.85      0.91      1272\n",
      "\n",
      "\n",
      "...................... l2 model........................................\n",
      "Accuracy: 0.8490566037735849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92      1254\n",
      "           1       0.06      0.67      0.11        18\n",
      "\n",
      "    accuracy                           0.85      1272\n",
      "   macro avg       0.53      0.76      0.51      1272\n",
      "weighted avg       0.98      0.85      0.91      1272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred={}\n",
    "for i in models.keys():\n",
    "    y_pred[i]=models[i].predict(X_test)\n",
    "    print(\"\\n......................\",i,\"model........................................\")\n",
    "    print(\"Accuracy:\",accuracy_score(y_pred[i],y_test))\n",
    "    print(classification_report(y_pred[i],y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f2010",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fdc33b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler,LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "818145c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27488f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline ={\n",
    "    \"enet\":make_pipeline(StandardScaler(),SimpleImputer(missing_values=np.nan,strategy='median'),LogisticRegression(penalty='elasticnet',max_iter=1000)),\n",
    "    \"l1\":make_pipeline(StandardScaler(),SimpleImputer(),LogisticRegression(penalty='l1',max_iter=1000)),\n",
    "    \"l2\":make_pipeline(StandardScaler(),SimpleImputer(),LogisticRegression(penalty='l2',max_iter=1000)),\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cd740a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_enet={\n",
    "    'logisticregression__l1_ratio':[0.2,0.5,0.8],\n",
    "    'logisticregression__C':[0.1,1,10], \n",
    "    'logisticregression__solver':['saga']\n",
    "    \n",
    "}\n",
    "\n",
    "param_l1={\n",
    "  'logisticregression__C':[0.1,1,10], \n",
    "  'logisticregression__solver':['liblinear','saga']\n",
    "    \n",
    "}\n",
    "\n",
    "param_l2={\n",
    "  'logisticregression__C':[0.1,1,10],    \n",
    "  'logisticregression__solver':['liblinear','saga']  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a5b8806",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper={\n",
    "    'enet':param_enet,\n",
    "    'l1':param_l1,\n",
    "    'l2':param_l2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d10e1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={}\n",
    "for i in pipeline.keys():\n",
    "    models[i]=BayesSearchCV(pipeline[i],hyper[i],cv=5,scoring=\"accuracy\",verbose=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30ac2318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet is trained and tuned\n",
      "l1 is trained and tuned\n",
      "l2 is trained and tuned\n"
     ]
    }
   ],
   "source": [
    "for i in models.keys():\n",
    "    models[i].fit(X_train_s,y_train_s)\n",
    "    print(i,\"is trained and tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d53bc130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".......................... enet model.........................................\n",
      "OrderedDict([('logisticregression__C', 1.0), ('logisticregression__l1_ratio', 0.5), ('logisticregression__solver', 'saga')])\n",
      "\n",
      ".......................... l1 model.........................................\n",
      "OrderedDict([('logisticregression__C', 1.0), ('logisticregression__solver', 'saga')])\n",
      "\n",
      ".......................... l2 model.........................................\n",
      "OrderedDict([('logisticregression__C', 10.0), ('logisticregression__solver', 'saga')])\n"
     ]
    }
   ],
   "source": [
    "for i in models.keys():\n",
    "    print(\"\\n..........................\",i,\"model.........................................\")\n",
    "    print(models[i].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1903fc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6525157232704403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.76       798\n",
      "           1       0.58      0.24      0.34       474\n",
      "\n",
      "    accuracy                           0.65      1272\n",
      "   macro avg       0.62      0.57      0.55      1272\n",
      "weighted avg       0.63      0.65      0.61      1272\n",
      "\n",
      "[[715  83]\n",
      " [359 115]]\n",
      "0.6525157232704403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.76       798\n",
      "           1       0.58      0.24      0.34       474\n",
      "\n",
      "    accuracy                           0.65      1272\n",
      "   macro avg       0.62      0.57      0.55      1272\n",
      "weighted avg       0.63      0.65      0.61      1272\n",
      "\n",
      "[[715  83]\n",
      " [359 115]]\n",
      "0.6509433962264151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.76       800\n",
      "           1       0.57      0.24      0.34       472\n",
      "\n",
      "    accuracy                           0.65      1272\n",
      "   macro avg       0.62      0.57      0.55      1272\n",
      "weighted avg       0.63      0.65      0.61      1272\n",
      "\n",
      "[[715  85]\n",
      " [359 113]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred={}\n",
    "for i in models.keys():\n",
    "    y_pred[i]=models[i].predict(X_test)\n",
    "    print(accuracy_score(y_pred[i],y_test))\n",
    "    print(classification_report(y_pred[i],y_test))\n",
    "    print(confusion_matrix(y_pred[i],y_test))\n",
    "#     print(i,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad019403",
   "metadata": {},
   "source": [
    "# PART 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d0278098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('imputer',SimpleImputer()),\n",
    "    ('classifier',LogisticRegression())\n",
    "    \n",
    "])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d7c950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid ={\n",
    "    \n",
    "    'classifier':[LogisticRegression(penalty='l1'),\n",
    "                  LogisticRegression(penalty='l2'),\n",
    "                  LogisticRegression(penalty='elasticnet'),\n",
    "                 \n",
    "                 ],\n",
    "    'classifier__C':[1,10,100],\n",
    "    'classifier__l1_ratio':[0.2,0.5,0.8],\n",
    "    'classifier__solver':['saga','liblinear'],\n",
    " \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "321ae2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(pipe,param_grid,cv=5,verbose=-1,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74670645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('imputer', SimpleImputer()),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid={'classifier': [LogisticRegression(C=1, l1_ratio=0.2,\n",
       "                                                           penalty='l1',\n",
       "                                                           solver='saga'),\n",
       "                                        LogisticRegression(),\n",
       "                                        LogisticRegression(penalty='elasticnet')],\n",
       "                         'classifier__C': [1, 10, 100],\n",
       "                         'classifier__l1_ratio': [0.2, 0.5, 0.8],\n",
       "                         'classifier__solver': ['saga', 'liblinear']},\n",
       "             scoring='accuracy', verbose=-1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cce5dfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('imputer', SimpleImputer()),\n",
      "                ('classifier',\n",
      "                 LogisticRegression(C=1, l1_ratio=0.2, penalty='l1',\n",
      "                                    solver='saga'))])\n",
      "{'classifier': LogisticRegression(C=1, l1_ratio=0.2, penalty='l1', solver='saga'), 'classifier__C': 1, 'classifier__l1_ratio': 0.2, 'classifier__solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "print(best_model)\n",
    "best_params=grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9d4a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f075754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model:LogisticRegression(C=1, l1_ratio=0.2, penalty='l1', solver='saga')\n",
      "Best Hyperparameters:{'classifier': LogisticRegression(C=1, l1_ratio=0.2, penalty='l1', solver='saga'), 'classifier__C': 1, 'classifier__l1_ratio': 0.2, 'classifier__solver': 'saga'}\n",
      "Accuracy:0.8498427672955975\n"
     ]
    }
   ],
   "source": [
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "print(f\"Best Model:{best_model.named_steps['classifier']}\")\n",
    "print(f\"Best Hyperparameters:{best_params}\")\n",
    "print(f\"Accuracy:{accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccbd03",
   "metadata": {},
   "source": [
    "# Part 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98ca217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pipeline=Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('classifier',RandomForestClassifier(),SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8fdf5c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "    'classifier':[RandomForestClassifier(),SVC()],\n",
    "#     'classifier__n_estimators':[50,100,200],\n",
    "#     'classifier__C':[1,10,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "510f28a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('imputer', SimpleImputer()),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid={'classifier': [RandomForestClassifier(), SVC()]})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search=GridSearchCV(pipe,param_grid,cv=5)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d999a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=grid_search.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5712af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('imputer', SimpleImputer()),\n",
      "                ('classifier', RandomForestClassifier())])\n",
      "{'classifier': RandomForestClassifier()}\n"
     ]
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "print(best_model)\n",
    "best_params=grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c15aef72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8482704402515723"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
