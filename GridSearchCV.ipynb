{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246f93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X,y = make_classification(n_classes= 2,n_samples=400,n_redundant=0,random_state=1)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76556a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold,cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84af3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "408bf6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf861a",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c18e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a6e587",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Exploring the GridSearchCV Class\n",
    "# GridSearchCV(\n",
    "#     estimator=,     # A sklearn model\n",
    "#     param_grid=,    # A dictionary of parameter names and values\n",
    "#     cv=,            # An integer that represents the number of k-folds\n",
    "#     scoring=,       # The performance measure (such as r2, precision)\n",
    "#     n_http://localhost:8888/notebooks/Untitled2.ipynb?kernel_name=python3#jobs=,        # The number of jobs to run in parallel\n",
    "#     verbose=        # Verbosity (0-3, with higher being more)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53c89b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c69f434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 'entropy', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873a01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hyper = {\n",
    "    \"max_depth\":np.arange(1,1000,10),\n",
    "    \"criterion\":['gini', 'log_loss','entropy',],\n",
    "    \"random_state\":np.arange(1,50,5),\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00cf0b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model=GridSearchCV(\n",
    "    estimator=model_dt,   \n",
    "    param_grid=hyper,   \n",
    "    cv=5,            \n",
    "    scoring='accuracy',   \n",
    "    n_jobs=5,    \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# grid_model=GridSearchCV(model_dt,hyper,cv=5,scoring='accuracy',n_jobs=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09595800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3000 candidates, totalling 15000 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=5,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121,\n",
       "       131, 141, 151, 161, 171, 181, 191, 201, 211, 221, 231, 241, 251,\n",
       "       261, 271, 281, 291, 301, 311, 321, 331, 341, 351, 361, 371, 381,\n",
       "       391, 401, 411, 421, 431, 441, 451, 461, 471, 481, 491, 501, 511,\n",
       "       521, 531, 541, 551, 561, 571, 581, 591, 601, 611, 621, 631, 641,\n",
       "       651, 661, 671, 681, 691, 701, 711, 721, 731, 741, 751, 761, 771,\n",
       "       781, 791, 801, 811, 821, 831, 841, 851, 861, 871, 881, 891, 901,\n",
       "       911, 921, 931, 941, 951, 961, 971, 981, 991]),\n",
       "                         &#x27;random_state&#x27;: array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46])},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=5,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121,\n",
       "       131, 141, 151, 161, 171, 181, 191, 201, 211, 221, 231, 241, 251,\n",
       "       261, 271, 281, 291, 301, 311, 321, 331, 341, 351, 361, 371, 381,\n",
       "       391, 401, 411, 421, 431, 441, 451, 461, 471, 481, 491, 501, 511,\n",
       "       521, 531, 541, 551, 561, 571, 581, 591, 601, 611, 621, 631, 641,\n",
       "       651, 661, 671, 681, 691, 701, 711, 721, 731, 741, 751, 761, 771,\n",
       "       781, 791, 801, 811, 821, 831, 841, 851, 861, 871, 881, 891, 901,\n",
       "       911, 921, 931, 941, 951, 961, 971, 981, 991]),\n",
       "                         &#x27;random_state&#x27;: array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46])},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=5,\n",
       "             param_grid={'criterion': ['gini', 'log_loss', 'entropy'],\n",
       "                         'max_depth': array([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121,\n",
       "       131, 141, 151, 161, 171, 181, 191, 201, 211, 221, 231, 241, 251,\n",
       "       261, 271, 281, 291, 301, 311, 321, 331, 341, 351, 361, 371, 381,\n",
       "       391, 401, 411, 421, 431, 441, 451, 461, 471, 481, 491, 501, 511,\n",
       "       521, 531, 541, 551, 561, 571, 581, 591, 601, 611, 621, 631, 641,\n",
       "       651, 661, 671, 681, 691, 701, 711, 721, 731, 741, 751, 761, 771,\n",
       "       781, 791, 801, 811, 821, 831, 841, 851, 861, 871, 881, 891, 901,\n",
       "       911, 921, 931, 941, 951, 961, 971, 981, 991]),\n",
       "                         'random_state': array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46])},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6aacc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'log_loss', 'max_depth': 1, 'random_state': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0477971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51bbcb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds=grid_model.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55c8cb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9416666666666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d830356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[51,  1],\n",
       "       [ 6, 62]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccdce569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9465648854961831"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28cf6f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.94        52\n",
      "           1       0.98      0.91      0.95        68\n",
      "\n",
      "    accuracy                           0.94       120\n",
      "   macro avg       0.94      0.95      0.94       120\n",
      "weighted avg       0.95      0.94      0.94       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69296f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    68\n",
       "0    52\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "spprt=pd.DataFrame(y_preds).value_counts(normalize=False)\n",
    "spprt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa9eaf1",
   "metadata": {},
   "source": [
    "# RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2828d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15bb3e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sklearn.grid_search.RandomizedSearchCV(estimator, \n",
    "                                             param_distributions=random_search, \n",
    "                                             n_iter=10, scoring=None, # Number of parameter combinations to try\n",
    "                                             fit_params=None,\n",
    "                                             n_jobs=1,Use all processors to compute in parallel \n",
    "                                             iid=True, \n",
    "                                             refit=True,\n",
    "                                              cv=None, Number of folds for k-fold validation \n",
    "                                             verbose=0, \n",
    "                                             pre_dispatch='2*n_jobs', \n",
    "                                             random_state=None, \n",
    "                                             error_score='raise'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb467bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomsearch= random_model=RandomizedSearchCV(\n",
    "                               estimator=model_dt,  \n",
    "                               param_distributions=hyper,\n",
    "                               cv=5,\n",
    "                               verbose=1,\n",
    "                               n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12a1c604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                      &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: array([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121,\n",
       "       131, 141, 151, 161, 171, 181, 191, 201, 211, 221, 231, 241, 251,\n",
       "       261, 271, 281, 291, 301, 311, 321, 331, 341, 351, 361, 371, 381,\n",
       "       391, 401, 411, 421, 431, 441, 451, 461, 471, 481, 491, 501, 511,\n",
       "       521, 531, 541, 551, 561, 571, 581, 591, 601, 611, 621, 631, 641,\n",
       "       651, 661, 671, 681, 691, 701, 711, 721, 731, 741, 751, 761, 771,\n",
       "       781, 791, 801, 811, 821, 831, 841, 851, 861, 871, 881, 891, 901,\n",
       "       911, 921, 931, 941, 951, 961, 971, 981, 991]),\n",
       "                                        &#x27;random_state&#x27;: array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46])},\n",
       "                   verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=1,\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;log_loss&#x27;,\n",
       "                                                      &#x27;entropy&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: array([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121,\n",
       "       131, 141, 151, 161, 171, 181, 191, 201, 211, 221, 231, 241, 251,\n",
       "       261, 271, 281, 291, 301, 311, 321, 331, 341, 351, 361, 371, 381,\n",
       "       391, 401, 411, 421, 431, 441, 451, 461, 471, 481, 491, 501, 511,\n",
       "       521, 531, 541, 551, 561, 571, 581, 591, 601, 611, 621, 631, 641,\n",
       "       651, 661, 671, 681, 691, 701, 711, 721, 731, 741, 751, 761, 771,\n",
       "       781, 791, 801, 811, 821, 831, 841, 851, 861, 871, 881, 891, 901,\n",
       "       911, 921, 931, 941, 951, 961, 971, 981, 991]),\n",
       "                                        &#x27;random_state&#x27;: array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46])},\n",
       "                   verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=1,\n",
       "                   param_distributions={'criterion': ['gini', 'log_loss',\n",
       "                                                      'entropy'],\n",
       "                                        'max_depth': array([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121,\n",
       "       131, 141, 151, 161, 171, 181, 191, 201, 211, 221, 231, 241, 251,\n",
       "       261, 271, 281, 291, 301, 311, 321, 331, 341, 351, 361, 371, 381,\n",
       "       391, 401, 411, 421, 431, 441, 451, 461, 471, 481, 491, 501, 511,\n",
       "       521, 531, 541, 551, 561, 571, 581, 591, 601, 611, 621, 631, 641,\n",
       "       651, 661, 671, 681, 691, 701, 711, 721, 731, 741, 751, 761, 771,\n",
       "       781, 791, 801, 811, 821, 831, 841, 851, 861, 871, 881, 891, 901,\n",
       "       911, 921, 931, 941, 951, 961, 971, 981, 991]),\n",
       "                                        'random_state': array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46])},\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf56f14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_state': 31, 'max_depth': 471, 'criterion': 'log_loss'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randomsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "596c9263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_preds=randomsearch.predict(X_test)\n",
    "y2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "083f1cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9083333333333333"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y2_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eecbca2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52,  6],\n",
       "       [ 5, 57]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y2_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "372cf6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.912"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y2_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dd01ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90        58\n",
      "           1       0.90      0.92      0.91        62\n",
      "\n",
      "    accuracy                           0.91       120\n",
      "   macro avg       0.91      0.91      0.91       120\n",
      "weighted avg       0.91      0.91      0.91       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_preds,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f61a21",
   "metadata": {},
   "source": [
    "# BayesianRandomhSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "caf9a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-optimize\n",
    "# !pip install git+https://github.com/scikit-optimize/scikit-optimize.git\n",
    "# import skops\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from scipy.stats import loguniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95dff08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real, Categorical, Integer\n",
    "classifier= DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "413b3e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     \"classifier__learning_rate\": loguniform(1e-4, 0.1),\n",
    "#     \"classifier__n_estimators\": randint(100,1000),\n",
    "#     \"classifier__max_depth\": randint(4, 400) \n",
    "# }\n",
    "\n",
    "# Random\n",
    "reg_rand = RandomizedSearchCV(\n",
    "                         classifier,\n",
    "                         param_distributions=hyper,\n",
    "#                          n_iter=n_iter,\n",
    "                         cv=5,\n",
    "                         n_jobs=1,\n",
    "                         scoring='accuracy',\n",
    "                         verbose=1\n",
    "                              )\n",
    "\n",
    "model_rand = reg_rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6eca6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_state': 1, 'max_depth': 551, 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rand.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d0c76d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_preds=model_rand.predict(X_test)\n",
    "y3_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "069230e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y3_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "512d1ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57,  0],\n",
       "       [ 0, 63]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y3_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "064939c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y3_preds,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a41f920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        57\n",
      "           1       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       120\n",
      "   macro avg       1.00      1.00      1.00       120\n",
      "weighted avg       1.00      1.00      1.00       120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y3_preds,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c1f08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _= opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b581e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skopt import BayesSearchCV\n",
    "# # parameter ranges are specified by one of below\n",
    "# from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # X, y = load_iris(True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "#                                                    train_size=0.75,\n",
    "#                                                     random_state=0)\n",
    "\n",
    "#  # log-uniform: understand as search over p = exp(x) by varying x\n",
    "# opt = BayesSearchCV(\n",
    "#    SVC(),\n",
    "#     {\n",
    "#         'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "#        'gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
    "#         'degree': Integer(1,8),\n",
    "#         'kernel': Categorical(['linear', 'poly', 'rbf']),\n",
    "#      },\n",
    "#    n_iter=32,\n",
    "#      random_state=0\n",
    "# )\n",
    "\n",
    "# # executes bayesian optimization\n",
    "# _ = opt.fit(X_train, y_train)\n",
    "\n",
    "#  # model can be saved, used for predictions or scoring\n",
    "# print(opt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e4f071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd1c9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cb900d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                   train_size=0.75,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ad2bbf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = BayesSearchCV(\n",
    "   SVC(),\n",
    "    {\n",
    "        'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "       'gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
    "        'degree': Integer(1,8),\n",
    "        'kernel': Categorical(['linear', 'poly', 'rbf']),\n",
    "     },\n",
    "   n_iter=32,\n",
    "     random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17410d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # executes bayesian optimization\n",
    "# _ = opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cc8b1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # model can be saved, used for predictions or scoring\n",
    "# print(opt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25e66127",
   "metadata": {},
   "outputs": [],
   "source": [
    "v=pd.DataFrame(y_preds)\n",
    "j=pd.DataFrame(y2_preds)\n",
    "l=pd.DataFrame(y3_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47395956",
   "metadata": {},
   "outputs": [],
   "source": [
    "vji=pd.concat(([v,j]),axis=1)\n",
    "vji.columns=[\"Prediction1\",\"Prediction2\"]\n",
    "vji=pd.concat([vji,l],axis=1)\n",
    "vji.columns=[\"Prediction1\",\"Prediction2\",\"Prediction3\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1f9ea129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prediction1  Prediction2\n",
      "19             1            0\n",
      "24             1            0\n",
      "75             1            0\n",
      "87             1            0\n",
      "93             1            0\n",
      "118            1            0\n"
     ]
    }
   ],
   "source": [
    "print(vji[(vji['Prediction1']-vji['Prediction2']==1) | (vji['Prediction1']-vji['Prediction2']==-1)].iloc[:,[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5ee4f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Prediction1  Prediction3\n",
      "27            1            0\n",
      "32            1            0\n",
      "45            0            1\n",
      "65            1            0\n",
      "68            1            0\n",
      "74            1            0\n",
      "87            1            0\n"
     ]
    }
   ],
   "source": [
    "print(vji[(vji['Prediction1']-vji['Prediction3']==1) | (vji['Prediction1']-vji['Prediction3']==-1)].iloc[:,[0,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "493c03b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Prediction1  Prediction3\n",
      "19             1            1\n",
      "24             1            1\n",
      "27             1            0\n",
      "32             1            0\n",
      "45             0            1\n",
      "65             1            0\n",
      "68             1            0\n",
      "74             1            0\n",
      "75             1            1\n",
      "93             1            1\n",
      "118            1            1\n"
     ]
    }
   ],
   "source": [
    "print(vji[(vji['Prediction2']-vji['Prediction3']==1) | (vji['Prediction2']-vji['Prediction3']==-1)].iloc[:,[0,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51ffaf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.996746</td>\n",
       "      <td>-2.484895</td>\n",
       "      <td>-0.575952</td>\n",
       "      <td>2.384293</td>\n",
       "      <td>0.341389</td>\n",
       "      <td>0.324869</td>\n",
       "      <td>-0.475650</td>\n",
       "      <td>-2.148997</td>\n",
       "      <td>-0.359021</td>\n",
       "      <td>0.436182</td>\n",
       "      <td>-1.214373</td>\n",
       "      <td>0.246853</td>\n",
       "      <td>-0.874541</td>\n",
       "      <td>-0.343500</td>\n",
       "      <td>-0.081702</td>\n",
       "      <td>-1.393557</td>\n",
       "      <td>1.208443</td>\n",
       "      <td>-0.569165</td>\n",
       "      <td>-0.824905</td>\n",
       "      <td>0.145388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.404769</td>\n",
       "      <td>-0.767909</td>\n",
       "      <td>-1.330030</td>\n",
       "      <td>0.243175</td>\n",
       "      <td>0.406133</td>\n",
       "      <td>0.187248</td>\n",
       "      <td>1.263359</td>\n",
       "      <td>-1.758870</td>\n",
       "      <td>0.564172</td>\n",
       "      <td>-0.518453</td>\n",
       "      <td>-0.635143</td>\n",
       "      <td>2.787361</td>\n",
       "      <td>0.006784</td>\n",
       "      <td>-0.139311</td>\n",
       "      <td>0.464322</td>\n",
       "      <td>1.580018</td>\n",
       "      <td>1.053783</td>\n",
       "      <td>0.258468</td>\n",
       "      <td>0.260543</td>\n",
       "      <td>-1.385539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.957391</td>\n",
       "      <td>-1.040540</td>\n",
       "      <td>1.412296</td>\n",
       "      <td>-1.193967</td>\n",
       "      <td>-0.129926</td>\n",
       "      <td>-2.285775</td>\n",
       "      <td>-0.157830</td>\n",
       "      <td>-0.015923</td>\n",
       "      <td>1.448543</td>\n",
       "      <td>-0.679315</td>\n",
       "      <td>0.400154</td>\n",
       "      <td>-1.102078</td>\n",
       "      <td>0.226002</td>\n",
       "      <td>2.717386</td>\n",
       "      <td>-1.121314</td>\n",
       "      <td>0.732108</td>\n",
       "      <td>0.477698</td>\n",
       "      <td>1.438281</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>0.629873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.949440</td>\n",
       "      <td>-0.819411</td>\n",
       "      <td>1.156107</td>\n",
       "      <td>-0.547322</td>\n",
       "      <td>-0.019117</td>\n",
       "      <td>-0.203386</td>\n",
       "      <td>1.424146</td>\n",
       "      <td>-1.189724</td>\n",
       "      <td>1.285717</td>\n",
       "      <td>0.166552</td>\n",
       "      <td>0.163424</td>\n",
       "      <td>-0.623277</td>\n",
       "      <td>-0.844528</td>\n",
       "      <td>-0.460537</td>\n",
       "      <td>0.947821</td>\n",
       "      <td>-0.605011</td>\n",
       "      <td>-0.454874</td>\n",
       "      <td>-2.108903</td>\n",
       "      <td>-0.387564</td>\n",
       "      <td>-0.342545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.271048</td>\n",
       "      <td>0.193059</td>\n",
       "      <td>-2.571591</td>\n",
       "      <td>0.239677</td>\n",
       "      <td>-1.256026</td>\n",
       "      <td>-0.110646</td>\n",
       "      <td>0.278080</td>\n",
       "      <td>-4.542827</td>\n",
       "      <td>0.334034</td>\n",
       "      <td>-0.426308</td>\n",
       "      <td>-1.716695</td>\n",
       "      <td>-0.663857</td>\n",
       "      <td>0.994198</td>\n",
       "      <td>-0.657083</td>\n",
       "      <td>-0.840332</td>\n",
       "      <td>-0.626635</td>\n",
       "      <td>1.513822</td>\n",
       "      <td>-0.032491</td>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.491127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.641585</td>\n",
       "      <td>0.221543</td>\n",
       "      <td>-1.161871</td>\n",
       "      <td>1.655217</td>\n",
       "      <td>0.406610</td>\n",
       "      <td>0.233406</td>\n",
       "      <td>1.653776</td>\n",
       "      <td>2.020592</td>\n",
       "      <td>-1.246745</td>\n",
       "      <td>0.365872</td>\n",
       "      <td>0.611944</td>\n",
       "      <td>0.217673</td>\n",
       "      <td>0.391605</td>\n",
       "      <td>-0.202189</td>\n",
       "      <td>-0.592053</td>\n",
       "      <td>-0.045796</td>\n",
       "      <td>-0.469671</td>\n",
       "      <td>-1.294483</td>\n",
       "      <td>0.710068</td>\n",
       "      <td>0.047745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.173680</td>\n",
       "      <td>-0.732032</td>\n",
       "      <td>0.380743</td>\n",
       "      <td>-0.697716</td>\n",
       "      <td>0.138595</td>\n",
       "      <td>2.084123</td>\n",
       "      <td>-2.003942</td>\n",
       "      <td>-0.856643</td>\n",
       "      <td>0.892588</td>\n",
       "      <td>-0.877247</td>\n",
       "      <td>-1.540079</td>\n",
       "      <td>1.303575</td>\n",
       "      <td>-0.080607</td>\n",
       "      <td>0.420593</td>\n",
       "      <td>0.317427</td>\n",
       "      <td>-0.198500</td>\n",
       "      <td>-0.044161</td>\n",
       "      <td>-0.129782</td>\n",
       "      <td>-1.087234</td>\n",
       "      <td>1.133613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.261575</td>\n",
       "      <td>-0.881258</td>\n",
       "      <td>1.160621</td>\n",
       "      <td>0.797587</td>\n",
       "      <td>-0.939589</td>\n",
       "      <td>-2.089441</td>\n",
       "      <td>-0.086479</td>\n",
       "      <td>0.476819</td>\n",
       "      <td>-0.568480</td>\n",
       "      <td>0.461626</td>\n",
       "      <td>-1.025365</td>\n",
       "      <td>-1.280209</td>\n",
       "      <td>-0.912972</td>\n",
       "      <td>0.648588</td>\n",
       "      <td>-1.434808</td>\n",
       "      <td>1.396319</td>\n",
       "      <td>-1.836104</td>\n",
       "      <td>-0.323274</td>\n",
       "      <td>-0.471558</td>\n",
       "      <td>0.660448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.640057</td>\n",
       "      <td>-0.633792</td>\n",
       "      <td>-0.921659</td>\n",
       "      <td>-0.745680</td>\n",
       "      <td>0.188583</td>\n",
       "      <td>0.560918</td>\n",
       "      <td>-0.430770</td>\n",
       "      <td>-1.054214</td>\n",
       "      <td>-1.258350</td>\n",
       "      <td>-0.417871</td>\n",
       "      <td>-1.070288</td>\n",
       "      <td>-0.447473</td>\n",
       "      <td>-1.407064</td>\n",
       "      <td>-0.113782</td>\n",
       "      <td>1.177070</td>\n",
       "      <td>-0.472876</td>\n",
       "      <td>-0.896880</td>\n",
       "      <td>0.944285</td>\n",
       "      <td>0.647375</td>\n",
       "      <td>1.386826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.723692</td>\n",
       "      <td>-1.141416</td>\n",
       "      <td>0.245179</td>\n",
       "      <td>-0.939431</td>\n",
       "      <td>1.124703</td>\n",
       "      <td>-1.639476</td>\n",
       "      <td>2.095819</td>\n",
       "      <td>0.631497</td>\n",
       "      <td>2.338143</td>\n",
       "      <td>0.927357</td>\n",
       "      <td>-0.072090</td>\n",
       "      <td>-1.445851</td>\n",
       "      <td>1.424365</td>\n",
       "      <td>0.257968</td>\n",
       "      <td>-0.697385</td>\n",
       "      <td>-0.816293</td>\n",
       "      <td>-1.130405</td>\n",
       "      <td>0.823185</td>\n",
       "      <td>1.058974</td>\n",
       "      <td>-1.144458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \n",
       "0  -1.996746 -2.484895 -0.575952  2.384293  0.341389  0.324869 -0.475650  \\\n",
       "1  -0.404769 -0.767909 -1.330030  0.243175  0.406133  0.187248  1.263359   \n",
       "2  -1.957391 -1.040540  1.412296 -1.193967 -0.129926 -2.285775 -0.157830   \n",
       "3  -0.949440 -0.819411  1.156107 -0.547322 -0.019117 -0.203386  1.424146   \n",
       "4   1.271048  0.193059 -2.571591  0.239677 -1.256026 -0.110646  0.278080   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95 -1.641585  0.221543 -1.161871  1.655217  0.406610  0.233406  1.653776   \n",
       "96  0.173680 -0.732032  0.380743 -0.697716  0.138595  2.084123 -2.003942   \n",
       "97 -1.261575 -0.881258  1.160621  0.797587 -0.939589 -2.089441 -0.086479   \n",
       "98  1.640057 -0.633792 -0.921659 -0.745680  0.188583  0.560918 -0.430770   \n",
       "99  0.723692 -1.141416  0.245179 -0.939431  1.124703 -1.639476  2.095819   \n",
       "\n",
       "          7         8         9         10        11        12        13   \n",
       "0  -2.148997 -0.359021  0.436182 -1.214373  0.246853 -0.874541 -0.343500  \\\n",
       "1  -1.758870  0.564172 -0.518453 -0.635143  2.787361  0.006784 -0.139311   \n",
       "2  -0.015923  1.448543 -0.679315  0.400154 -1.102078  0.226002  2.717386   \n",
       "3  -1.189724  1.285717  0.166552  0.163424 -0.623277 -0.844528 -0.460537   \n",
       "4  -4.542827  0.334034 -0.426308 -1.716695 -0.663857  0.994198 -0.657083   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  2.020592 -1.246745  0.365872  0.611944  0.217673  0.391605 -0.202189   \n",
       "96 -0.856643  0.892588 -0.877247 -1.540079  1.303575 -0.080607  0.420593   \n",
       "97  0.476819 -0.568480  0.461626 -1.025365 -1.280209 -0.912972  0.648588   \n",
       "98 -1.054214 -1.258350 -0.417871 -1.070288 -0.447473 -1.407064 -0.113782   \n",
       "99  0.631497  2.338143  0.927357 -0.072090 -1.445851  1.424365  0.257968   \n",
       "\n",
       "          14        15        16        17        18        19  \n",
       "0  -0.081702 -1.393557  1.208443 -0.569165 -0.824905  0.145388  \n",
       "1   0.464322  1.580018  1.053783  0.258468  0.260543 -1.385539  \n",
       "2  -1.121314  0.732108  0.477698  1.438281  0.698800  0.629873  \n",
       "3   0.947821 -0.605011 -0.454874 -2.108903 -0.387564 -0.342545  \n",
       "4  -0.840332 -0.626635  1.513822 -0.032491  0.830995  0.491127  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "95 -0.592053 -0.045796 -0.469671 -1.294483  0.710068  0.047745  \n",
       "96  0.317427 -0.198500 -0.044161 -0.129782 -1.087234  1.133613  \n",
       "97 -1.434808  1.396319 -1.836104 -0.323274 -0.471558  0.660448  \n",
       "98  1.177070 -0.472876 -0.896880  0.944285  0.647375  1.386826  \n",
       "99 -0.697385 -0.816293 -1.130405  0.823185  1.058974 -1.144458  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx=pd.DataFrame(X_test)\n",
    "xx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3870e314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.382766</td>\n",
       "      <td>-0.401759</td>\n",
       "      <td>1.222996</td>\n",
       "      <td>-1.163063</td>\n",
       "      <td>-0.457645</td>\n",
       "      <td>1.031118</td>\n",
       "      <td>0.363118</td>\n",
       "      <td>1.364129</td>\n",
       "      <td>-0.614908</td>\n",
       "      <td>-1.077009</td>\n",
       "      <td>0.419161</td>\n",
       "      <td>0.088642</td>\n",
       "      <td>0.080526</td>\n",
       "      <td>0.805295</td>\n",
       "      <td>0.462314</td>\n",
       "      <td>-1.379569</td>\n",
       "      <td>1.946349</td>\n",
       "      <td>0.031152</td>\n",
       "      <td>-0.814204</td>\n",
       "      <td>-0.301463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.148937</td>\n",
       "      <td>0.058098</td>\n",
       "      <td>-0.008131</td>\n",
       "      <td>1.049827</td>\n",
       "      <td>-0.293695</td>\n",
       "      <td>1.336392</td>\n",
       "      <td>-1.353253</td>\n",
       "      <td>0.563943</td>\n",
       "      <td>-1.172663</td>\n",
       "      <td>-0.581251</td>\n",
       "      <td>3.118480</td>\n",
       "      <td>0.351517</td>\n",
       "      <td>0.623651</td>\n",
       "      <td>-0.435145</td>\n",
       "      <td>-0.617073</td>\n",
       "      <td>-0.214191</td>\n",
       "      <td>0.983467</td>\n",
       "      <td>-1.372419</td>\n",
       "      <td>-0.443988</td>\n",
       "      <td>0.305031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-1.288487</td>\n",
       "      <td>-0.373687</td>\n",
       "      <td>0.841409</td>\n",
       "      <td>0.450585</td>\n",
       "      <td>0.661060</td>\n",
       "      <td>0.989528</td>\n",
       "      <td>-1.068135</td>\n",
       "      <td>0.328059</td>\n",
       "      <td>1.300321</td>\n",
       "      <td>-0.416476</td>\n",
       "      <td>0.364444</td>\n",
       "      <td>-0.022161</td>\n",
       "      <td>-0.007400</td>\n",
       "      <td>-0.534328</td>\n",
       "      <td>-0.331306</td>\n",
       "      <td>0.645128</td>\n",
       "      <td>-0.111816</td>\n",
       "      <td>1.548697</td>\n",
       "      <td>-2.925305</td>\n",
       "      <td>0.585105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.551323</td>\n",
       "      <td>-0.512483</td>\n",
       "      <td>-0.258695</td>\n",
       "      <td>0.548488</td>\n",
       "      <td>0.088120</td>\n",
       "      <td>-0.628069</td>\n",
       "      <td>0.242411</td>\n",
       "      <td>-2.410303</td>\n",
       "      <td>-0.732807</td>\n",
       "      <td>-0.768158</td>\n",
       "      <td>0.260688</td>\n",
       "      <td>-0.233441</td>\n",
       "      <td>2.301635</td>\n",
       "      <td>0.500320</td>\n",
       "      <td>-1.215225</td>\n",
       "      <td>-1.111373</td>\n",
       "      <td>-1.060274</td>\n",
       "      <td>0.313962</td>\n",
       "      <td>-0.904289</td>\n",
       "      <td>1.628239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-0.550871</td>\n",
       "      <td>-0.486735</td>\n",
       "      <td>0.617037</td>\n",
       "      <td>-1.200913</td>\n",
       "      <td>-0.539159</td>\n",
       "      <td>-1.461658</td>\n",
       "      <td>-1.220669</td>\n",
       "      <td>-0.299420</td>\n",
       "      <td>0.837728</td>\n",
       "      <td>-1.300110</td>\n",
       "      <td>0.278067</td>\n",
       "      <td>0.417224</td>\n",
       "      <td>-0.644936</td>\n",
       "      <td>0.046424</td>\n",
       "      <td>-0.275215</td>\n",
       "      <td>0.064998</td>\n",
       "      <td>-1.077913</td>\n",
       "      <td>0.318884</td>\n",
       "      <td>-1.220435</td>\n",
       "      <td>0.452660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.327751</td>\n",
       "      <td>-0.899702</td>\n",
       "      <td>-0.782005</td>\n",
       "      <td>0.405069</td>\n",
       "      <td>-0.665696</td>\n",
       "      <td>0.903518</td>\n",
       "      <td>-0.590562</td>\n",
       "      <td>0.222473</td>\n",
       "      <td>0.163965</td>\n",
       "      <td>-0.081397</td>\n",
       "      <td>1.738585</td>\n",
       "      <td>-1.395863</td>\n",
       "      <td>-0.360068</td>\n",
       "      <td>0.304355</td>\n",
       "      <td>1.295183</td>\n",
       "      <td>1.598200</td>\n",
       "      <td>0.134388</td>\n",
       "      <td>-1.196205</td>\n",
       "      <td>-0.287442</td>\n",
       "      <td>0.293720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \n",
       "27  2.382766 -0.401759  1.222996 -1.163063 -0.457645  1.031118  0.363118  \\\n",
       "32 -0.148937  0.058098 -0.008131  1.049827 -0.293695  1.336392 -1.353253   \n",
       "65 -1.288487 -0.373687  0.841409  0.450585  0.661060  0.989528 -1.068135   \n",
       "68 -0.551323 -0.512483 -0.258695  0.548488  0.088120 -0.628069  0.242411   \n",
       "74 -0.550871 -0.486735  0.617037 -1.200913 -0.539159 -1.461658 -1.220669   \n",
       "87  0.327751 -0.899702 -0.782005  0.405069 -0.665696  0.903518 -0.590562   \n",
       "\n",
       "          7         8         9         10        11        12        13   \n",
       "27  1.364129 -0.614908 -1.077009  0.419161  0.088642  0.080526  0.805295  \\\n",
       "32  0.563943 -1.172663 -0.581251  3.118480  0.351517  0.623651 -0.435145   \n",
       "65  0.328059  1.300321 -0.416476  0.364444 -0.022161 -0.007400 -0.534328   \n",
       "68 -2.410303 -0.732807 -0.768158  0.260688 -0.233441  2.301635  0.500320   \n",
       "74 -0.299420  0.837728 -1.300110  0.278067  0.417224 -0.644936  0.046424   \n",
       "87  0.222473  0.163965 -0.081397  1.738585 -1.395863 -0.360068  0.304355   \n",
       "\n",
       "          14        15        16        17        18        19  \n",
       "27  0.462314 -1.379569  1.946349  0.031152 -0.814204 -0.301463  \n",
       "32 -0.617073 -0.214191  0.983467 -1.372419 -0.443988  0.305031  \n",
       "65 -0.331306  0.645128 -0.111816  1.548697 -2.925305  0.585105  \n",
       "68 -1.215225 -1.111373 -1.060274  0.313962 -0.904289  1.628239  \n",
       "74 -0.275215  0.064998 -1.077913  0.318884 -1.220435  0.452660  \n",
       "87  1.295183  1.598200  0.134388 -1.196205 -0.287442  0.293720  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.iloc[[27,32,65,68,74,87],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41a028a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
